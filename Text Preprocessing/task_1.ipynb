{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Reconstruct the Original Meeting Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Student Name: Vipul Krishnan Muralee Dharan\n",
    "#### Student ID: 28104641\n",
    "\n",
    "Date: 02/06/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.6.1 and Anaconda 4.3.21 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "* bs4 v4.6.0(for xml retrievel)\n",
    "* os (comes with python) (for retrieving file list in the folder)\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "The original meeting transcripts are stored in three different types of XML files, which are ending with \".words.xml\", \".topic.xml\" and \".segments.xml\". (The details about the three types of files can be found in Section 3 below). The task here is to reconstruct the original meeting transcripts with the corresponding topical and paragraph boundaries from these files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup is used to easily retrive data from the xml files (Crummy, 2018).\n",
    "\n",
    "os is used to find the files inside the computer folders (Python Software Foundation, 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Required Variables and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the path variables for easiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining path variables\n",
    "topic_file_path = \"./topics\" \n",
    "word_file_path = \"./words\" \n",
    "segment_file_path = \"./segments\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the main function which takes the filename of the topic file as an input and fetches the text for that particular file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the main function which integrates the text for a topic file and \n",
    "# saves it as a .txt file\n",
    "def getTopics(tfile):\n",
    "    \n",
    "    # initilizing the text content as empty\n",
    "    text = \"\"\n",
    "    \n",
    "    # a dictionary store the entire text related to the current tipic file\n",
    "    # key is the word file id\n",
    "    vocD = {}\n",
    "    \n",
    "    # a dictionary to store the segment breaks\n",
    "    # to be used to find the place where to insert new lines\n",
    "    mapD = {}\n",
    "    \n",
    "    # opening the topic file in beutiful soap\n",
    "    tSoup = bsoup(open(\"./topics/\"+tfile), 'lxml')\n",
    "    \n",
    "    # fetch all word files...\n",
    "    for wfile in os.listdir(word_file_path):\n",
    "        # ..which is related to the current topic file\n",
    "        if wfile.split('.')[0] == tfile.split('.')[0]:\n",
    "            # insert all text (found using the function getWords) into the vocD dictionary\n",
    "            vocD[wfile.split('.')[0]+'.'+wfile.split('.')[1]] = getWords(wfile.split('.')[0]+'.'+wfile.split('.')[1])\n",
    "    \n",
    "    # fetch all segment files..\n",
    "    for sfile in os.listdir(segment_file_path):\n",
    "        # .. which are related to the current topic file\n",
    "        if sfile.split('.')[0] == tfile.split('.')[0]:\n",
    "            # find the beginning of the segments (using the function getMapping) and add to segment directory\n",
    "            mapD[sfile.split('.')[0]+'.'+sfile.split('.')[1]] = getMapping(sfile.split('.')[0]+'.'+sfile.split('.')[1])\n",
    "    \n",
    "    # for each topic in the topic file..\n",
    "    for topic in tSoup.find(\"nite:root\").findAll('topic', recursive=False):\n",
    "        # .. retrieve the text of the topic using getTopic function and add it to the text variable\n",
    "        # vocD and mapD are passed as attributes.\n",
    "        text = text + \" \" + getTopic(topic, vocD, mapD).strip() + \"\\n\"\n",
    "    \n",
    "    # once all the topics are completed, write the text variable into txt file    \n",
    "    f= open(\"txt_files/\"+ tfile.split('.')[0] + \".txt\",\"w+\")\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function simpy iterate through the topics in it and call getTopic function to get the topic text. Pleas Once all the topic texts are collected, it writes into the file.\n",
    "\n",
    "Please note that the text and segment breaks are collected as common dictionaries so that the getTopic function does not have to open the files again and again. This decreases the code running time very much and takes around 2 minutes only.\n",
    "\n",
    "we now define, getWords function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the function takes the word file reference as the parameter and returns all words in it\n",
    "# the index of the word in the returned list is equal to its ID\n",
    "def getWords(id):\n",
    "    \n",
    "    # list for words\n",
    "    wList = []\n",
    "    \n",
    "    # missing word verifier\n",
    "    # some of the word numbers are missing. This is used to correct \n",
    "    verify = 0 \n",
    "    \n",
    "    # opens the file in bsoup\n",
    "    WSoup = bsoup(open(word_file_path+'/'+id+\".words.xml\"), 'lxml')\n",
    "    \n",
    "    # for each word..\n",
    "    for word in WSoup.find(\"nite:root\").findAll():\n",
    "        #.. word id is collected\n",
    "        wordid = word['nite:id'].split('words')[-1]\n",
    "        \n",
    "        # if the wordid is not digits, give up this iteration\n",
    "        # this is to make sure that the wordx tags are not considered\n",
    "        if not wordid.isdigit():\n",
    "            continue\n",
    "            \n",
    "        # missing word verification\n",
    "        # if a mismatch between the id of word and the maintained count\n",
    "        if int(word['nite:id'].split('words')[-1]) != verify:\n",
    "            # add empty strings to list to adjust\n",
    "            for i in range(int(word['nite:id'].split('words')[-1]) - verify): \n",
    "                wList.append(\"\")\n",
    "            verify = int(word['nite:id'].split('words')[-1])\n",
    "        \n",
    "        # if there is a word in the tag value, add that word\n",
    "        if word.string != None:\n",
    "            wList.append(word.string.strip())\n",
    "        # else append an empty string\n",
    "        else:\n",
    "            wList.append(\"\")\n",
    "        \n",
    "        # verification count increases\n",
    "        verify = verify + 1\n",
    "        \n",
    "    return wList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a word list curresponding to a word file where the index of the word in the list is the id of the word.\n",
    "\n",
    "Now we define the getMapping function. This function obtains the details of segment breaks and we can use this data to put line breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function returns a list containing the id of the words which are the starting of a segment\n",
    "def getMapping(id):\n",
    "    \n",
    "    # the reurn list\n",
    "    retList = []\n",
    "    \n",
    "    # opening the file using the bsoup\n",
    "    SSoup = bsoup(open(segment_file_path+'/'+id+\".segments.xml\"), 'lxml')\n",
    "    \n",
    "    # for each segment in the file..\n",
    "    for segment in SSoup.find(\"nite:root\").findAll('segment'):\n",
    "        #... find the starting word of the segment\n",
    "        hrefArray = segment.find('nite:child')['href'].split('.')\n",
    "        # add the id of the word to the list\n",
    "        retList.append(int(hrefArray[5][5:-1]))\n",
    "    \n",
    "    # return the list\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function simply finds the word ids with which the segments starts and append it to a list. This list can be used when making the entire text. Whenever a word comes in the text whose id is in the above obtained list, we will have to put a line break there.\n",
    "\n",
    "Now we define the getTopic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function obtains the complete text for a single topic\n",
    "# it receives the vocD, and mapD from the calling function\n",
    "# isSub attibutes specifies if the topic is main topic or subtopic\n",
    "def getTopic(topic, vocD, mapD, isSub=0):\n",
    "    \n",
    "    # the text to be returned\n",
    "    ttext = \"\"\n",
    "    \n",
    "    # find all the child s in the topic tag non recursively  \n",
    "    for y in topic.findAll(recursive=False):\n",
    "        \n",
    "        # if it is a subtopic, call the function recursively again with isSub=1\n",
    "        if y.name == 'topic':\n",
    "            ttext = ttext.strip() + \"\\n \" + getTopic(y, vocD, mapD,1).strip() + '\\n'\n",
    "            \n",
    "        # if it is a child element\n",
    "        elif y.name == 'nite:child':\n",
    "            # separate different parts in the href section of the element\n",
    "            hrefArray = y['href'].split('.')\n",
    "            \n",
    "            # if the child element contains more than one word (ie if it is a range)\n",
    "            if len(hrefArray) > 7:\n",
    "                # for each word id in that range \n",
    "                for i in range(int(hrefArray[5][5:-1]), int(hrefArray[9][5:-1])+1):\n",
    "                    # .. checks if the word is start of a segment, if yes a new line char is inserted\n",
    "                    if i in mapD[hrefArray[0]+'.'+hrefArray[1]]:\n",
    "                        ttext = ttext.strip() + '\\n'\n",
    "                    # .. the word curresponding to the id is obtained from vocD and appended to the ttext\n",
    "                    ttext = (ttext.strip(\" \") + \" \" + vocD[hrefArray[0]+'.'+hrefArray[1]][i].strip() if vocD[hrefArray[0]+'.'+hrefArray[1]][i] != \"\" else ttext)\n",
    "            \n",
    "            # if there is only one word in the child elememnt\n",
    "            elif len(hrefArray) > 3:\n",
    "                # check if that word is the start of a segment, if yes ass a new line\n",
    "                if (int(hrefArray[5][5:-1]) in mapD[hrefArray[0]+'.'+hrefArray[1]]):\n",
    "                    ttext = ttext.strip() + '\\n'\n",
    "                # find the word from the vocD dictionary using the id and append\n",
    "                ttext = (ttext.strip(\" \") + \" \" + vocD[hrefArray[0]+'.'+hrefArray[1]][int(hrefArray[5][5:-1])] if vocD[hrefArray[0]+'.'+hrefArray[1]][int(hrefArray[5][5:-1])] != \"\" else ttext)# if vocList[int(hrefArray[5][5:-1])] != \"<expression>\" else \"\"\n",
    "            ttext = ttext.strip() + '\\n'\n",
    "    \n",
    "    # if it is not a subtopic, add the topic boundary\n",
    "    if isSub != 1:\n",
    "        ttext = ttext.strip() + \"\\n**********\\n\"\n",
    "    \n",
    "    # return the text\n",
    "    return ttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calling the Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For executing the task, we find each topic files in the topic folder and call getTopics of function with each file name. This completes the whole task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES2002a.topic.xml : Done!\n",
      "ES2002b.topic.xml : Done!\n",
      "ES2002c.topic.xml : Done!\n",
      "ES2002d.topic.xml : Done!\n",
      "ES2003a.topic.xml : Done!\n",
      "ES2003b.topic.xml : Done!\n",
      "ES2003c.topic.xml : Done!\n",
      "ES2003d.topic.xml : Done!\n",
      "ES2004a.topic.xml : Done!\n",
      "ES2004b.topic.xml : Done!\n",
      "ES2004c.topic.xml : Done!\n",
      "ES2004d.topic.xml : Done!\n",
      "ES2005a.topic.xml : Done!\n",
      "ES2005b.topic.xml : Done!\n",
      "ES2005c.topic.xml : Done!\n",
      "ES2005d.topic.xml : Done!\n",
      "ES2006a.topic.xml : Done!\n",
      "ES2006b.topic.xml : Done!\n",
      "ES2006d.topic.xml : Done!\n",
      "ES2007a.topic.xml : Done!\n",
      "ES2007b.topic.xml : Done!\n",
      "ES2007c.topic.xml : Done!\n",
      "ES2007d.topic.xml : Done!\n",
      "ES2008a.topic.xml : Done!\n",
      "ES2008b.topic.xml : Done!\n",
      "ES2008c.topic.xml : Done!\n",
      "ES2008d.topic.xml : Done!\n",
      "ES2009a.topic.xml : Done!\n",
      "ES2009b.topic.xml : Done!\n",
      "ES2009c.topic.xml : Done!\n",
      "ES2009d.topic.xml : Done!\n",
      "ES2010a.topic.xml : Done!\n",
      "ES2010b.topic.xml : Done!\n",
      "ES2010c.topic.xml : Done!\n",
      "ES2010d.topic.xml : Done!\n",
      "ES2011a.topic.xml : Done!\n",
      "ES2011b.topic.xml : Done!\n",
      "ES2011c.topic.xml : Done!\n",
      "ES2011d.topic.xml : Done!\n",
      "ES2012a.topic.xml : Done!\n",
      "ES2012b.topic.xml : Done!\n",
      "ES2012c.topic.xml : Done!\n",
      "ES2012d.topic.xml : Done!\n",
      "ES2013a.topic.xml : Done!\n",
      "ES2013b.topic.xml : Done!\n",
      "ES2013c.topic.xml : Done!\n",
      "ES2013d.topic.xml : Done!\n",
      "ES2014a.topic.xml : Done!\n",
      "ES2014b.topic.xml : Done!\n",
      "ES2014c.topic.xml : Done!\n",
      "ES2014d.topic.xml : Done!\n",
      "ES2015a.topic.xml : Done!\n",
      "ES2015d.topic.xml : Done!\n",
      "ES2016a.topic.xml : Done!\n",
      "ES2016b.topic.xml : Done!\n",
      "ES2016c.topic.xml : Done!\n",
      "ES2016d.topic.xml : Done!\n",
      "IB4003.topic.xml : Done!\n",
      "IB4005.topic.xml : Done!\n",
      "IB4010.topic.xml : Done!\n",
      "IB4011.topic.xml : Done!\n",
      "IS1000a.topic.xml : Done!\n",
      "IS1000b.topic.xml : Done!\n",
      "IS1000c.topic.xml : Done!\n",
      "IS1000d.topic.xml : Done!\n",
      "IS1001a.topic.xml : Done!\n",
      "IS1001b.topic.xml : Done!\n",
      "IS1001c.topic.xml : Done!\n",
      "IS1001d.topic.xml : Done!\n",
      "IS1002b.topic.xml : Done!\n",
      "IS1002c.topic.xml : Done!\n",
      "IS1002d.topic.xml : Done!\n",
      "IS1003a.topic.xml : Done!\n",
      "IS1003b.topic.xml : Done!\n",
      "IS1003c.topic.xml : Done!\n",
      "IS1003d.topic.xml : Done!\n",
      "IS1004a.topic.xml : Done!\n",
      "IS1004b.topic.xml : Done!\n",
      "IS1004c.topic.xml : Done!\n",
      "IS1004d.topic.xml : Done!\n",
      "IS1005a.topic.xml : Done!\n",
      "IS1005b.topic.xml : Done!\n",
      "IS1005c.topic.xml : Done!\n",
      "IS1006a.topic.xml : Done!\n",
      "IS1006b.topic.xml : Done!\n",
      "IS1006c.topic.xml : Done!\n",
      "IS1006d.topic.xml : Done!\n",
      "IS1007a.topic.xml : Done!\n",
      "IS1007b.topic.xml : Done!\n",
      "IS1007c.topic.xml : Done!\n",
      "IS1007d.topic.xml : Done!\n",
      "IS1008a.topic.xml : Done!\n",
      "IS1008b.topic.xml : Done!\n",
      "IS1008c.topic.xml : Done!\n",
      "IS1008d.topic.xml : Done!\n",
      "IS1009a.topic.xml : Done!\n",
      "IS1009b.topic.xml : Done!\n",
      "IS1009c.topic.xml : Done!\n",
      "IS1009d.topic.xml : Done!\n",
      "TS3003a.topic.xml : Done!\n",
      "TS3003b.topic.xml : Done!\n",
      "TS3003c.topic.xml : Done!\n",
      "TS3003d.topic.xml : Done!\n",
      "TS3004a.topic.xml : Done!\n",
      "TS3004b.topic.xml : Done!\n",
      "TS3004c.topic.xml : Done!\n",
      "TS3004d.topic.xml : Done!\n",
      "TS3005a.topic.xml : Done!\n",
      "TS3005b.topic.xml : Done!\n",
      "TS3005c.topic.xml : Done!\n",
      "TS3005d.topic.xml : Done!\n",
      "TS3006a.topic.xml : Done!\n",
      "TS3006b.topic.xml : Done!\n",
      "TS3006c.topic.xml : Done!\n",
      "TS3006d.topic.xml : Done!\n",
      "TS3007a.topic.xml : Done!\n",
      "TS3007b.topic.xml : Done!\n",
      "TS3007c.topic.xml : Done!\n",
      "TS3007d.topic.xml : Done!\n",
      "TS3008a.topic.xml : Done!\n",
      "TS3008b.topic.xml : Done!\n",
      "TS3008c.topic.xml : Done!\n",
      "TS3008d.topic.xml : Done!\n",
      "TS3009a.topic.xml : Done!\n",
      "TS3009b.topic.xml : Done!\n",
      "TS3009c.topic.xml : Done!\n",
      "TS3009d.topic.xml : Done!\n",
      "TS3010a.topic.xml : Done!\n",
      "TS3010b.topic.xml : Done!\n",
      "TS3010c.topic.xml : Done!\n",
      "TS3010d.topic.xml : Done!\n",
      "TS3011a.topic.xml : Done!\n",
      "TS3011b.topic.xml : Done!\n",
      "TS3011c.topic.xml : Done!\n",
      "TS3011d.topic.xml : Done!\n",
      "TS3012a.topic.xml : Done!\n",
      "TS3012b.topic.xml : Done!\n",
      "TS3012c.topic.xml : Done!\n",
      "TS3012d.topic.xml : Done!\n"
     ]
    }
   ],
   "source": [
    "# for each file in the topic folder\n",
    "for tfile in os.listdir(topic_file_path): \n",
    "    tfile = os.path.join(topic_file_path, tfile)\n",
    "    # checking if the file is xml file\n",
    "    if os.path.isfile(tfile) and tfile.endswith('.xml'):\n",
    "        # taking only the file name\n",
    "        tfile = tfile.split('\\\\')[-1]\n",
    "        # calling the getTopic function\n",
    "        getTopics(tfile)\n",
    "        print(tfile + \" : Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole task completes in 1 to 2 minutes depending on the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "The text for all the topic files are obtained from curresponding word files, inserted the segment breaks according to the segment file datails and saved as txt files. The overall task takes 2 - 3 minutes depending on the running machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Crummy. (2018). 'Beautiful Soup Documentation'. Retrieved from https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- Python Software Foundation. (2018). \"Miscellaneous operating system interfaces\". Retrieved from https://docs.python.org/3.4/library/os.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
